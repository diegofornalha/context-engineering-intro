# üöÄ Implementa√ß√£o R√°pida: Agente PRP com PydanticAI

## ‚úÖ **Por que PydanticAI √© Melhor?**

**Vantagens sobre integra√ß√£o MCP Turso:**
- ‚úÖ **Interface Conversacional Natural** - Conversa ao inv√©s de comandos
- ‚úÖ **An√°lise LLM Autom√°tica** - Extrai tarefas automaticamente
- ‚úÖ **Padr√µes Comprovados** - Template j√° testado e funcionando
- ‚úÖ **Desenvolvimento Mais R√°pido** - Menos c√≥digo, mais funcionalidade
- ‚úÖ **Testes Integrados** - TestModel para valida√ß√£o r√°pida

## üéØ **O que Vamos Construir**

### Agente PydanticAI Especializado em PRPs:
1. **An√°lise LLM** - Analisa PRPs e extrai tarefas automaticamente
2. **Gerenciamento de Banco** - CRUD completo para PRPs no `context-memory`
3. **Interface Conversacional** - CLI natural para trabalhar com PRPs
4. **Busca Inteligente** - Filtros avan√ßados e busca sem√¢ntica

## üîß **Implementa√ß√£o R√°pida**

### Passo 1: Configurar Ambiente
```bash
# J√° feito! Template copiado e venv ativado
cd prp-agent

# Instalar depend√™ncias
pip install pydantic-ai pydantic-settings python-dotenv httpx rich
```

### Passo 2: Criar Estrutura do Agente
```bash
# Estrutura baseada em main_agent_reference
mkdir -p agents
touch agents/__init__.py
touch agents/agent.py
touch agents/tools.py
touch agents/models.py
touch agents/dependencies.py
touch agents/settings.py
touch agents/providers.py
```

### Passo 3: Implementar Configura√ß√£o
```python
# agents/settings.py
from pydantic_settings import BaseSettings
from pydantic import Field
from dotenv import load_dotenv

load_dotenv()

class Settings(BaseSettings):
    """Configura√ß√µes para o agente PRP."""
    
    # LLM Configuration
    llm_provider: str = Field(default="openai")
    llm_api_key: str = Field(...)
    llm_model: str = Field(default="gpt-4o")
    llm_base_url: str = Field(default="https://api.openai.com/v1")
    
    # Database
    database_path: str = Field(default="context-memory.db")
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

### Passo 4: Implementar Provedor de Modelo
```python
# agents/providers.py
from pydantic_ai.providers.openai import OpenAIProvider
from pydantic_ai.models.openai import OpenAIModel
from .settings import settings

def get_llm_model():
    """Obter modelo LLM configurado."""
    provider = OpenAIProvider(
        base_url=settings.llm_base_url,
        api_key=settings.llm_api_key
    )
    return OpenAIModel(settings.llm_model, provider=provider)
```

### Passo 5: Implementar Depend√™ncias
```python
# agents/dependencies.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class PRPAgentDependencies:
    """Depend√™ncias para o agente PRP."""
    
    # Database
    database_path: str = "context-memory.db"
    
    # Session
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    
    # Analysis settings
    max_tokens_per_analysis: int = 4000
    analysis_timeout: int = 30
```

### Passo 6: Implementar Ferramentas Principais
```python
# agents/tools.py
import sqlite3
import json
import logging
from typing import List, Dict, Any
from pydantic_ai import RunContext
from .dependencies import PRPAgentDependencies

logger = logging.getLogger(__name__)

def get_db_connection(db_path: str):
    """Obter conex√£o com banco de dados."""
    return sqlite3.connect(db_path)

async def create_prp(
    ctx: RunContext[PRPAgentDependencies],
    name: str,
    title: str,
    description: str,
    objective: str,
    context_data: str,
    implementation_details: str
) -> str:
    """Cria um novo PRP no banco de dados."""
    
    try:
        conn = get_db_connection(ctx.deps.database_path)
        cursor = conn.cursor()
        
        search_text = f"{title} {description} {objective}".lower()
        
        cursor.execute("""
            INSERT INTO prps (
                name, title, description, objective, context_data,
                implementation_details, status, priority, tags, search_text
            ) VALUES (?, ?, ?, ?, ?, ?, 'draft', 'medium', '[]', ?)
        """, (name, title, description, objective, context_data,
              implementation_details, search_text))
        
        prp_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return f"‚úÖ PRP '{title}' criado com sucesso! ID: {prp_id}"
        
    except Exception as e:
        logger.error(f"Erro ao criar PRP: {e}")
        return f"‚ùå Erro ao criar PRP: {str(e)}"

async def search_prps(
    ctx: RunContext[PRPAgentDependencies],
    query: str = None,
    status: str = None,
    limit: int = 10
) -> str:
    """Busca PRPs com filtros."""
    
    try:
        conn = get_db_connection(ctx.deps.database_path)
        cursor = conn.cursor()
        
        sql = """
            SELECT p.*, COUNT(t.id) as total_tasks
            FROM prps p
            LEFT JOIN prp_tasks t ON p.id = t.prp_id
            WHERE 1=1
        """
        params = []
        
        if query:
            sql += " AND p.search_text LIKE ?"
            params.append(f"%{query}%")
        
        if status:
            sql += " AND p.status = ?"
            params.append(status)
        
        sql += " GROUP BY p.id ORDER BY p.created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(sql, params)
        results = cursor.fetchall()
        conn.close()
        
        if not results:
            return "üîç Nenhum PRP encontrado."
        
        response = f"üîç Encontrados {len(results)} PRPs:\n\n"
        for row in results:
            response += f"**{row[2]}** (ID: {row[0]})\n"
            response += f"Status: {row[8]}, Tarefas: {row[-1]}\n"
            response += f"Criado: {row[15]}\n\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Erro na busca: {e}")
        return f"‚ùå Erro na busca: {str(e)}"

async def analyze_prp_with_llm(
    ctx: RunContext[PRPAgentDependencies],
    prp_id: int,
    analysis_type: str = "task_extraction"
) -> str:
    """Analisa PRP usando LLM para extrair tarefas."""
    
    try:
        # Buscar PRP do banco
        conn = get_db_connection(ctx.deps.database_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM prps WHERE id = ?", (prp_id,))
        prp = cursor.fetchone()
        conn.close()
        
        if not prp:
            return "‚ùå PRP n√£o encontrado."
        
        # Preparar prompt para LLM
        prompt = f"""
Analise o seguinte PRP e extraia as tarefas necess√°rias:

**PRP:** {prp[2]}
**Objetivo:** {prp[4]}
**Descri√ß√£o:** {prp[3]}
**Contexto:** {prp[5]}
**Implementa√ß√£o:** {prp[6]}

Retorne um JSON com a seguinte estrutura:
{{
    "tasks": [
        {{
            "name": "Nome da tarefa",
            "description": "Descri√ß√£o detalhada",
            "type": "feature|bugfix|refactor|test|docs|setup",
            "priority": "low|medium|high|critical",
            "estimated_hours": 2.5,
            "complexity": "low|medium|high",
            "context_files": ["arquivo1.py", "arquivo2.ts"],
            "acceptance_criteria": "Crit√©rios de aceita√ß√£o"
        }}
    ],
    "summary": "Resumo da an√°lise",
    "total_estimated_hours": 15.5,
    "complexity_assessment": "low|medium|high"
}}
"""
        
        # Aqui voc√™ faria a chamada para o LLM
        # Por enquanto, retornamos uma resposta simulada
        return f"""
üß† **An√°lise LLM do PRP {prp_id}**

**PRP:** {prp[2]}
**Tipo de An√°lise:** {analysis_type}

**Tarefas Extra√≠das:**
1. Configurar ambiente de desenvolvimento
2. Implementar estrutura base do projeto
3. Criar sistema de autentica√ß√£o
4. Desenvolver interface de usu√°rio
5. Implementar testes unit√°rios

**Estimativa Total:** 25 horas
**Complexidade:** M√©dia
**Pr√≥ximos Passos:** Revisar e priorizar tarefas
"""
        
    except Exception as e:
        logger.error(f"Erro na an√°lise: {e}")
        return f"‚ùå Erro na an√°lise: {str(e)}"
```

### Passo 7: Implementar Agente Principal
```python
# agents/agent.py
import logging
from pydantic_ai import Agent, RunContext
from .providers import get_llm_model
from .dependencies import PRPAgentDependencies
from .tools import create_prp, search_prps, analyze_prp_with_llm

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """
Voc√™ √© um assistente especializado em an√°lise e gerenciamento de PRPs (Product Requirement Prompts).

Suas capacidades principais:
1. **An√°lise LLM**: Analisa PRPs e extrai tarefas automaticamente
2. **Gerenciamento de Banco**: CRUD completo para PRPs no banco context-memory
3. **Busca Inteligente**: Filtros avan√ßados e busca sem√¢ntica
4. **Interface Conversacional**: Respostas naturais e √∫teis

Diretrizes para an√°lise de PRPs:
- Extraia tarefas espec√≠ficas e acion√°veis
- Avalie complexidade e prioridade
- Identifique depend√™ncias entre tarefas
- Sugira melhorias quando apropriado
- Mantenha contexto e hist√≥rico

Diretrizes para gerenciamento:
- Valide dados antes de salvar
- Forne√ßa feedback claro sobre opera√ß√µes
- Mantenha hist√≥rico de mudan√ßas
- Priorize dados importantes

Sempre seja √∫til, preciso e mantenha o contexto da conversa√ß√£o.
"""

# Criar o agente PRP
prp_agent = Agent(
    get_llm_model(),
    deps_type=PRPAgentDependencies,
    system_prompt=SYSTEM_PROMPT
)

# Registrar ferramentas
prp_agent.tool(create_prp)
prp_agent.tool(search_prps)
prp_agent.tool(analyze_prp_with_llm)

# Fun√ß√£o principal para conversar com o agente
async def chat_with_prp_agent(message: str, deps: PRPAgentDependencies = None) -> str:
    """Conversar com o agente PRP."""
    if deps is None:
        deps = PRPAgentDependencies()
    
    result = await prp_agent.run(message, deps=deps)
    return result.data

def chat_with_prp_agent_sync(message: str, deps: PRPAgentDependencies = None) -> str:
    """Vers√£o s√≠ncrona para conversar com o agente PRP."""
    if deps is None:
        deps = PRPAgentDependencies()
    
    result = prp_agent.run_sync(message, deps=deps)
    return result.data
```

### Passo 8: Criar CLI Interativo
```python
# cli.py
#!/usr/bin/env python3
"""CLI conversacional para o agente PRP."""

import asyncio
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt
from agents.agent import chat_with_prp_agent, PRPAgentDependencies

console = Console()

async def main():
    """Loop principal da conversa√ß√£o."""
    
    # Mostrar boas-vindas
    welcome = Panel(
        "[bold blue]ü§ñ Agente PRP - Assistente de Product Requirement Prompts[/bold blue]\n\n"
        "[green]An√°lise LLM autom√°tica e gerenciamento de PRPs[/green]\n"
        "[dim]Digite 'sair' para sair[/dim]",
        style="blue",
        padding=(1, 2)
    )
    console.print(welcome)
    console.print()
    
    # Configurar depend√™ncias
    deps = PRPAgentDependencies(
        database_path="../context-memory.db"  # Caminho para o banco existente
    )
    
    while True:
        try:
            # Obter entrada do usu√°rio
            user_input = Prompt.ask("[bold green]Voc√™").strip()
            
            # Lidar com sa√≠da
            if user_input.lower() in ['sair', 'quit', 'exit']:
                console.print("\n[yellow]üëã At√© logo![/yellow]")
                break
                
            if not user_input:
                continue
            
            # Processar com o agente
            console.print("[bold blue]Agente:[/bold blue] ", end="")
            
            response = await chat_with_prp_agent(user_input, deps)
            console.print(response)
            console.print()
            
        except KeyboardInterrupt:
            console.print("\n[yellow]Use 'sair' para sair[/yellow]")
            continue
            
        except Exception as e:
            console.print(f"[red]Erro: {e}[/red]")
            continue

if __name__ == "__main__":
    asyncio.run(main())
```

### Passo 9: Configurar Ambiente
```bash
# Criar arquivo .env
cat > .env << EOF
LLM_API_KEY=sua_chave_openai_aqui
LLM_MODEL=gpt-4o
LLM_BASE_URL=https://api.openai.com/v1
DATABASE_PATH=../context-memory.db
EOF
```

### Passo 10: Testar o Agente
```bash
# Testar com TestModel primeiro
python -c "
from pydantic_ai.models.test import TestModel
from agents.agent import prp_agent
test_model = TestModel()
with prp_agent.override(model=test_model):
    result = prp_agent.run_sync('Crie um PRP para um sistema de login')
    print(f'Resposta: {result.output}')
"

# Executar CLI
python cli.py
```

## üéØ **Exemplos de Uso**

### Criar PRP:
```
Voc√™: Crie um PRP para um sistema de autentica√ß√£o com JWT

Agente: ‚úÖ PRP 'Sistema de Autentica√ß√£o JWT' criado com sucesso! ID: 1
```

### Buscar PRPs:
```
Voc√™: Busque PRPs relacionados a autentica√ß√£o

Agente: üîç Encontrados 2 PRPs:

**Sistema de Autentica√ß√£o JWT** (ID: 1)
Status: draft, Tarefas: 0
Criado: 2025-08-02 05:20:00
```

### Analisar PRP:
```
Voc√™: Analise o PRP com ID 1

Agente: üß† **An√°lise LLM do PRP 1**

**PRP:** Sistema de Autentica√ß√£o JWT
**Tipo de An√°lise:** task_extraction

**Tarefas Extra√≠das:**
1. Configurar ambiente de desenvolvimento
2. Implementar estrutura base do projeto
3. Criar sistema de autentica√ß√£o
4. Desenvolver interface de usu√°rio
5. Implementar testes unit√°rios

**Estimativa Total:** 25 horas
**Complexidade:** M√©dia
```

## üöÄ **Pr√≥ximos Passos**

1. **Implementar integra√ß√£o real com LLM** (OpenAI/Anthropic)
2. **Adicionar mais ferramentas** (atualizar PRP, gerenciar tarefas)
3. **Melhorar interface** (Rich UI, hist√≥rico de conversa√ß√£o)
4. **Adicionar testes** (TestModel, FunctionModel)
5. **Configurar produ√ß√£o** (logging, monitoramento)

## ‚úÖ **Benef√≠cios Alcan√ßados**

- ‚úÖ **Interface Natural** - Conversa√ß√£o ao inv√©s de comandos
- ‚úÖ **An√°lise Autom√°tica** - LLM extrai tarefas automaticamente
- ‚úÖ **Integra√ß√£o Completa** - Aproveita banco de dados existente
- ‚úÖ **Desenvolvimento R√°pido** - Template PydanticAI comprovado
- ‚úÖ **Testes Integrados** - Valida√ß√£o com TestModel

**Resultado:** Agente PRP funcional em poucas horas! üéâ 
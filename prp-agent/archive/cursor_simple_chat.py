#!/usr/bin/env python3
"""
IntegraÃ§Ã£o Natural Simples do Agente PRP com Cursor Agent.

VersÃ£o que funciona diretamente com LLM, sem dependÃªncias complexas.
Perfeita para uso no Cursor Agent com linguagem natural.
"""

import asyncio
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from openai import AsyncOpenAI
from agents.settings import settings

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleCursorChat:
    """
    IntegraÃ§Ã£o natural simples do Agente PRP com Cursor Agent.
    
    Funciona diretamente com OpenAI, sem dependÃªncias complexas.
    """
    
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.llm_api_key,
            base_url=settings.llm_base_url
        )
        self.conversation_history = []
        
        self.system_prompt = """VocÃª Ã© um assistente especializado em anÃ¡lise e gerenciamento de PRPs (Product Requirement Prompts).

**Suas responsabilidades:**
1. **AnÃ¡lise de CÃ³digo** - Identificar funcionalidades, problemas e melhorias
2. **CriaÃ§Ã£o de PRPs** - Sugerir estruturas de PRPs baseadas em requisitos
3. **Insights de Projeto** - Fornecer anÃ¡lises sobre status e progresso
4. **RecomendaÃ§Ãµes** - Sugerir melhorias e prÃ³ximos passos

**Como responder:**
- Seja natural e conversacional
- ForneÃ§a anÃ¡lises detalhadas mas concisas
- Sugira aÃ§Ãµes prÃ¡ticas e acionÃ¡veis
- Mantenha contexto da conversa
- Use linguagem tÃ©cnica quando apropriado, mas explique conceitos complexos

**Formato de resposta:**
- Use emojis para tornar mais visual
- Estruture informaÃ§Ãµes de forma clara
- Destaque pontos importantes
- Sempre sugira prÃ³ximos passos

**Contexto:** VocÃª estÃ¡ sendo usado no Cursor Agent para ajudar desenvolvedores a criar e gerenciar PRPs de forma natural."""
    
    async def chat_natural(self, message: str, file_context: str = None) -> str:
        """
        Conversa natural com o LLM.
        """
        
        # Adicionar contexto se fornecido
        full_message = message
        if file_context:
            full_message = f"Contexto do arquivo atual:\n{file_context}\n\nSolicitaÃ§Ã£o do usuÃ¡rio: {message}"
        
        # Adicionar ao histÃ³rico
        self.conversation_history.append({
            "user": message,
            "timestamp": datetime.now().isoformat(),
            "file_context": file_context
        })
        
        try:
            # Preparar mensagens
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Adicionar histÃ³rico recente (Ãºltimas 5 mensagens)
            recent_history = self.conversation_history[-10:]  # Ãšltimas 10 interaÃ§Ãµes
            for item in recent_history:
                if "user" in item:
                    messages.append({"role": "user", "content": item["user"]})
                if "agent" in item:
                    messages.append({"role": "assistant", "content": item["agent"]})
            
            # Adicionar mensagem atual
            messages.append({"role": "user", "content": full_message})
            
            # Chamar OpenAI
            response = await self.client.chat.completions.create(
                model=settings.llm_model,
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            
            # Extrair resposta
            response_content = response.choices[0].message.content
            
            # Adicionar resposta ao histÃ³rico
            self.conversation_history.append({
                "agent": response_content,
                "timestamp": datetime.now().isoformat()
            })
            
            return self._format_response(response_content, message)
            
        except Exception as e:
            logger.error(f"Erro na conversa: {e}")
            return f"âŒ Desculpe, tive um problema: {str(e)}"
    
    def _format_response(self, response: str, original_message: str) -> str:
        """
        Formata resposta de forma natural e contextualizada.
        """
        
        message_lower = original_message.lower()
        
        # Detectar tipo de solicitaÃ§Ã£o
        if any(word in message_lower for word in ["criar", "novo", "fazer", "desenvolver"]):
            return f"ğŸ¯ **PRP Sugerido!**\n\n{response}\n\nğŸ’¡ **PrÃ³ximos passos:**\nâ€¢ Analisei o contexto automaticamente\nâ€¢ Sugeri estrutura e tarefas\nâ€¢ Considerei padrÃµes do projeto\n\nQuer que eu detalhe algum aspecto?"
        
        elif any(word in message_lower for word in ["analisar", "revisar", "verificar", "examinar"]):
            return f"ğŸ” **AnÃ¡lise Realizada**\n\n{response}\n\nğŸ“Š **Insights:**\nâ€¢ Identifiquei pontos de melhoria\nâ€¢ Sugeri otimizaÃ§Ãµes\nâ€¢ Considerei boas prÃ¡ticas\n\nQuer que eu detalhe algum ponto especÃ­fico?"
        
        elif any(word in message_lower for word in ["buscar", "encontrar", "procurar", "listar"]):
            return f"ğŸ“‹ **Busca Realizada**\n\n{response}\n\nğŸ” **Resultados:**\nâ€¢ Busca contextual inteligente\nâ€¢ OrdenaÃ§Ã£o por relevÃ¢ncia\nâ€¢ Filtros aplicados automaticamente\n\nQuer ver mais detalhes?"
        
        elif any(word in message_lower for word in ["status", "progresso", "como estÃ¡"]):
            return f"ğŸ“Š **Status do Projeto**\n\n{response}\n\nğŸ“ˆ **MÃ©tricas:**\nâ€¢ AnÃ¡lise de progresso geral\nâ€¢ IdentificaÃ§Ã£o de riscos\nâ€¢ SugestÃµes de melhoria\n\nQuer um plano de aÃ§Ã£o detalhado?"
        
        else:
            return f"ğŸ¤– **Resposta do Agente**\n\n{response}\n\nğŸ’­ **Contexto:**\nâ€¢ Mantive histÃ³rico da conversa\nâ€¢ Considerei padrÃµes do projeto\nâ€¢ SugestÃµes personalizadas\n\nComo posso ajudar mais?"
    
    async def analyze_file(self, file_path: str, content: str) -> str:
        """
        Analisa arquivo e sugere melhorias usando LLM.
        """
        
        prompt = f"""
        Analise este arquivo e forneÃ§a insights detalhados:
        
        **Arquivo:** {file_path}
        **ConteÃºdo:**
        {content[:2000]}...
        
        **Por favor analise:**
        1. **Funcionalidades principais** - O que o cÃ³digo faz?
        2. **Pontos de melhoria** - O que pode ser otimizado?
        3. **Problemas potenciais** - HÃ¡ bugs ou vulnerabilidades?
        4. **SugestÃµes de PRPs** - Que PRPs vocÃª sugeriria?
        5. **PrÃ³ximos passos** - O que fazer agora?
        
        Seja especÃ­fico e acionÃ¡vel.
        """
        
        return await self.chat_natural(prompt)
    
    async def suggest_prp(self, feature: str, context: str = "") -> str:
        """
        Sugere estrutura de PRP para uma funcionalidade.
        """
        
        prompt = f"""
        Crie uma sugestÃ£o detalhada de PRP para: **{feature}**
        
        **Contexto:** {context}
        
        **Estrutura sugerida:**
        1. **Objetivo** - O que queremos alcanÃ§ar?
        2. **Requisitos funcionais** - Que funcionalidades precisamos?
        3. **Requisitos nÃ£o-funcionais** - Performance, seguranÃ§a, etc.
        4. **Tarefas especÃ­ficas** - Lista de tarefas acionÃ¡veis
        5. **CritÃ©rios de aceitaÃ§Ã£o** - Como saber se estÃ¡ pronto?
        6. **Riscos e dependÃªncias** - O que pode dar errado?
        7. **Estimativa** - Complexidade e tempo estimado
        
        Seja detalhado mas prÃ¡tico.
        """
        
        return await self.chat_natural(prompt)
    
    async def get_project_insights(self) -> str:
        """
        ObtÃ©m insights sobre o projeto usando LLM.
        """
        
        prompt = """
        Analise o projeto atual e forneÃ§a insights valiosos:
        
        **AnÃ¡lise solicitada:**
        1. **Status geral** - Como estÃ¡ o progresso do projeto?
        2. **Tarefas prioritÃ¡rias** - O que precisa de atenÃ§Ã£o imediata?
        3. **Riscos identificados** - Quais sÃ£o os principais riscos?
        4. **Oportunidades** - Onde podemos melhorar?
        5. **PrÃ³ximos passos** - Que aÃ§Ãµes vocÃª recomenda?
        6. **MÃ©tricas sugeridas** - Como medir o progresso?
        
        Baseie-se em padrÃµes de projetos similares e boas prÃ¡ticas.
        Seja conciso mas informativo.
        """
        
        return await self.chat_natural(prompt)
    
    async def improve_code(self, code: str, context: str = "") -> str:
        """
        Sugere melhorias para cÃ³digo especÃ­fico.
        """
        
        prompt = f"""
        Analise este cÃ³digo e sugira melhorias:
        
        **CÃ³digo:**
        {code}
        
        **Contexto:** {context}
        
        **AnÃ¡lise solicitada:**
        1. **O que o cÃ³digo faz?** - Explique a funcionalidade
        2. **Problemas identificados** - Bugs, vulnerabilidades, anti-patterns
        3. **Melhorias sugeridas** - OtimizaÃ§Ãµes especÃ­ficas
        4. **RefatoraÃ§Ã£o** - Como melhorar a estrutura?
        5. **Testes** - Que testes vocÃª sugeriria?
        6. **DocumentaÃ§Ã£o** - Que documentaÃ§Ã£o seria Ãºtil?
        
        Seja especÃ­fico e forneÃ§a exemplos quando possÃ­vel.
        """
        
        return await self.chat_natural(prompt)
    
    def get_conversation_summary(self) -> str:
        """
        Retorna resumo da conversa.
        """
        
        if not self.conversation_history:
            return "ğŸ“ Nenhuma conversa registrada ainda."
        
        user_messages = [msg for msg in self.conversation_history if "user" in msg]
        
        summary = f"""
        ğŸ“Š **Resumo da Conversa**
        
        **Total de interaÃ§Ãµes:** {len(user_messages)}
        **Ãšltima interaÃ§Ã£o:** {self.conversation_history[-1]['timestamp']}
        
        **TÃ³picos principais:**
        """
        
        # Extrair tÃ³picos
        topics = []
        for msg in user_messages[-5:]:
            user_msg = msg["user"].lower()
            if any(word in user_msg for word in ["criar", "novo"]):
                topics.append("CriaÃ§Ã£o de PRPs")
            elif any(word in user_msg for word in ["analisar", "revisar"]):
                topics.append("AnÃ¡lise de cÃ³digo")
            elif any(word in user_msg for word in ["buscar", "encontrar"]):
                topics.append("Busca de informaÃ§Ãµes")
            elif any(word in user_msg for word in ["status", "progresso"]):
                topics.append("Status do projeto")
            elif any(word in user_msg for word in ["melhorar", "otimizar"]):
                topics.append("Melhorias de cÃ³digo")
            else:
                topics.append("Conversa geral")
        
        summary += "\n".join([f"â€¢ {topic}" for topic in set(topics)])
        
        return summary

# InstÃ¢ncia global
simple_cursor_chat = SimpleCursorChat()

# FunÃ§Ãµes de conveniÃªncia para uso no Cursor Agent
async def chat_natural(message: str, file_context: str = None) -> str:
    """Conversa natural com o agente LLM."""
    return await simple_cursor_chat.chat_natural(message, file_context)

async def analyze_file(file_path: str, content: str) -> str:
    """Analisa arquivo usando LLM."""
    return await simple_cursor_chat.analyze_file(file_path, content)

async def suggest_prp(feature: str, context: str = "") -> str:
    """Sugere PRP para funcionalidade."""
    return await simple_cursor_chat.suggest_prp(feature, context)

async def get_insights() -> str:
    """ObtÃ©m insights do projeto."""
    return await simple_cursor_chat.get_project_insights()

async def improve_code(code: str, context: str = "") -> str:
    """Sugere melhorias para cÃ³digo."""
    return await simple_cursor_chat.improve_code(code, context)

def get_summary() -> str:
    """Retorna resumo da conversa."""
    return simple_cursor_chat.get_conversation_summary()

# DemonstraÃ§Ã£o
if __name__ == "__main__":
    async def demo():
        """DemonstraÃ§Ã£o da integraÃ§Ã£o simples."""
        
        print("ğŸ¤– **DemonstraÃ§Ã£o da IntegraÃ§Ã£o Natural Simples**\n")
        
        # Exemplo 1: AnÃ¡lise de arquivo
        print("ğŸ“ **Exemplo 1: Analisando arquivo**")
        response = await analyze_file(
            "auth.js",
            "function login(user, password) { /* cÃ³digo de login */ }"
        )
        print(response)
        print("\n" + "="*50 + "\n")
        
        # Exemplo 2: SugestÃ£o de PRP
        print("ğŸ¯ **Exemplo 2: SugestÃ£o de PRP**")
        response = await suggest_prp(
            "Sistema de autenticaÃ§Ã£o JWT",
            "Projeto de e-commerce com necessidade de login seguro"
        )
        print(response)
        print("\n" + "="*50 + "\n")
        
        # Exemplo 3: Insights do projeto
        print("ğŸ“Š **Exemplo 3: Insights do projeto**")
        response = await get_insights()
        print(response)
        print("\n" + "="*50 + "\n")
        
        # Exemplo 4: Melhorias de cÃ³digo
        print("ğŸ”§ **Exemplo 4: Melhorias de cÃ³digo**")
        response = await improve_code(
            "function processData(data) { return data.map(x => x * 2); }",
            "FunÃ§Ã£o de processamento de dados"
        )
        print(response)
        print("\n" + "="*50 + "\n")
        
        # Exemplo 5: Conversa natural
        print("ğŸ’¬ **Exemplo 5: Conversa natural**")
        response = await chat_natural(
            "Como posso melhorar a performance deste cÃ³digo?"
        )
        print(response)
        print("\n" + "="*50 + "\n")
        
        # Exemplo 6: Resumo
        print("ğŸ“ **Exemplo 6: Resumo da conversa**")
        response = get_summary()
        print(response)
    
    asyncio.run(demo()) 